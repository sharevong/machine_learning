{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "1. 预备知识\n",
    "    \n",
    "    1.1 什么是机器学习\n",
    "    \n",
    "    1.2 特征类型\n",
    "    \n",
    "    1.3 其它知识点\n",
    "\n",
    "2. 算法\n",
    "\n",
    "    2.1 分类算法\n",
    "\n",
    "    2.2 回归算法\n",
    "\n",
    "    2.3 聚类算法\n",
    "\n",
    "3. 模型评估\n",
    "\n",
    "    3.1 交叉验证\n",
    "\n",
    "    3.2 过采样与欠采样（Upsampling vs Downsampling）\n",
    "\n",
    "    3.3 F1-score\n",
    "    \n",
    "    3.4 ROC曲线\n",
    "    \n",
    "4. 案例讲解\n",
    "\n",
    "    4.1 机器学习问题解题步骤\n",
    "    \n",
    "    4.2 商务签违规预测\n",
    "    \n",
    "    4.3 销量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是机器学习\n",
    "\n",
    "以下是Andrew Ng在cousera机器学习课程上给出的定义：\n",
    "\n",
    "```\n",
    "Arthur Samuel(1959). Machine Learning: Field of study that give computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "Tom Mitchell(1998) Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\n",
    "```\n",
    "\n",
    "机器学习算法按照是否需要标签数据分为：\n",
    "\n",
    "1. 监督学习（Supervised learning）。分类、回归都属于监督学习方法；\n",
    "\n",
    "    1.1 半监督学习（Semi-supervised learning)。利用少量标注数据和大量未标注数据进行学习。GAN（Generative Adversarial Networks）属于这类算法；\n",
    "    \n",
    "    1.2 主动学习（Active learning）。半监督学习的特例，可以在没有太多数据的情况下，算法通过不断给出在决策边界上的样本，让打标者进行打标，使得算法明确分类边界，该算法结合online的使用和灰度测试等方法，可以有大量无标签数据和大量用户资源的时候，从无到有地创建良好的分类器；\n",
    "    \n",
    "    1.3 增强学习（Reinforcement learning）。训练数据以回报或惩罚的形式作为在动态环境中采取某种操作的反馈；\n",
    "\n",
    "2. 非监督学习（Unsupervised learning）。比如聚类、PCA、LDA等就属于非监督学习方法；\n",
    "\n",
    "按照应用领域分为：\n",
    "\n",
    "1. 分类问题。输出的目标变量为Categorial变量，分类问题包括：二分类问题（binary classifier）、多分类问题（multi-class classifier）和多标签问题（multi-label classifier）。\n",
    "\n",
    "2. 回归问题。输出的目标变量为Continous变量。\n",
    "\n",
    "3. 聚类问题。将输入划分到不同的组，但事先并不知道有哪些组。\n",
    "\n",
    "4. 数据降维。将输入映射到低维数据空间。\n",
    "\n",
    "5. 关联分析。Apriori算法。\n",
    "\n",
    "6. 密度估计（density estimation）。\n",
    "\n",
    "-- <cite>[Machine learning wikipedia](https://en.wikipedia.org/wiki/Machine_learning)<cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征类型\n",
    "\n",
    "1. 二元属性（Flag）。只有2个值的属性，有的资料叫做Dummy variable； \n",
    "2. 标称属性（Nominal）。具有多个属性值的属性。\n",
    "3. 序数属性（Ordinal）。具有多个具有顺序属性值的属性，比如高中低。\n",
    "4. 连续属性（Continuous）。具有连续值的属性。\n",
    "\n",
    "其中1-3都叫做分类属性（Categorical）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其它知识点\n",
    "\n",
    "### 范式（Norm）\n",
    "\n",
    "$\\ell_1$ norm: ${\\parallel x \\parallel}_1 = \\sum\\limits_{i=1}^{n}|x_i|$  \n",
    "\n",
    "$\\ell_2$ norm: ${\\parallel x \\parallel}_2 = \\sum\\limits_{i=1}^{n}x_i^2$  \n",
    "\n",
    "### hyperparameter\n",
    "\n",
    "hyperparameter: 在机器学习中，是指需要人工设定的参数。通过算法自动从数据中学习的参数叫parameter。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类算法\n",
    "\n",
    "### 决策树（Decision Tree）\n",
    "\n",
    "![Decision Tree](./Decision_Tree.png)\n",
    "\n",
    "\n",
    "相关概念：\n",
    "\n",
    "1. Root Node：代表整个训练数据集合；\n",
    "2. Splitting：分割，根据一定规则将节点分割成多个子节点，使每个节点更纯。\n",
    "3. Decision Node：可进一步分割的节点；\n",
    "4. Leaf/Terminal Node：叶子节点；\n",
    "5. Pruning：剪枝，删除掉某个节点的子节点；\n",
    "6. Branch/Sub-Tree\n",
    "\n",
    "常见的决策树算法包括*ID3*, *C4.5*, *CART*，其中Hunt算法是这些算法的基础，Hunt算法通过将训练记录相继划分成较纯的子集，递归地建立决策树。设$D_t$是与节点t关联的训练记录，$y={y_1,y_2,\\dots,y_c}$是类标号，则Hunt算法递归定义如下：\n",
    "\n",
    "1. 如果$D_t$中所有记录属于同一个类$y_t$，则t是叶子节点，用$y_t$标记；\n",
    "2. 如果$D_t$中包含属于多个类的记录，则选择一个属性测试条件，将记录划分成较小的自己。对于测试条件的每个输出，创建一个子节点，并根据测试结果将$D_t$中记录分布到子节点中，然后对子节点递归调用Hunt算法。\n",
    "\n",
    "为了确定属性测试条件，需要比较父节点与划分后子节点的不纯度的差别，差别越大，测试条件越好。增益$\\Delta$用来确定划分效果的标准：\n",
    "\n",
    "$\\Delta = I(parent) - \\sum\\limits_{j=1}^{k}\\frac{N(v_j)}{N}I(v_j)$\n",
    "\n",
    "其中$I(.)$是给定节点的不纯性度量，$N$是父节点上记录总数，$k$是属性值的个数，$N(v_j)$表示与节点$v_j$关联的记录个数。常用的不纯性度量包括熵（Entropy）、Gini系数和分类误差。当使用熵作为增益的度量时，又叫做信息增益。\n",
    "\n",
    "熵：$Entropy(t) = -\\sum\\limits_{i=0}^{c-1}p(i|t)log_2{p(i|t)}$  \n",
    "Gini系数：$Gini(t) = 1 - \\sum\\limits_{i=0}^{c-1}[p(i|t)]^2$  \n",
    "分类误差：$Classification\\ error(t) = 1 - max_i{[p(i|t)]}$  \n",
    "\n",
    "其中$c$是类的个数，$p(i|t)$表示给定节点t中属于类i的记录所占的比例。\n",
    "\n",
    "ID3（Iterative Dichotomiser 3）：该算法可以创建多路树（multiway tree），基于最大信息增益找到最佳的分类属性。树先增长到最大，然后再剪枝。\n",
    "\n",
    "C4.5：是ID3的改进算法，移除了ID3属性必须是分类属性的限制，可以自动将连续属性切分成分类属性；可以处理缺失值；可以将生成的tree转换成if-then规则集合；提升了计算效率；\n",
    "\n",
    "C5.0：C4.5的改进算法，相对于C4.5，在提升准确度同时，使用更小的规则集合提升了计算效率，并减少了内存占用；\n",
    "\n",
    "CART（Classification and Regression Tree）：与C4.5算法类似，但它可以用来解决回归问题，不会生成规则集合，并且使用二叉树进行决策树的构造；\n",
    "\n",
    "scikit-learn的DecisionTreeClassifier采用的是CART算法。\n",
    "\n",
    "#### 优点\n",
    "\n",
    "1. 理解简单，规则易解释；  \n",
    "2. 较少的数据准备，不需要归一化和二值化。但sklearn的CART算法不支持缺失值；  \n",
    "3. 模型预测性能与训练决策树所使用的训练集数据成对数比例关系；  \n",
    "4. 能够同时处理连续类型和分类类型特征；  \n",
    "\n",
    "#### 缺点\n",
    "\n",
    "1. 容易过拟合。需要设置合适的剪枝规则，避免过拟合；  \n",
    "2. 不稳定，数据集的一些小波动可能导致完全不同的树的生成。这个问题可以采用组合方法减轻；\n",
    "3. 决策树优化过程是一个NP完全问题，只能达到局部最优，而不能实现全局最优。可以采用组合的方法来减轻；\n",
    "4. 当数据不平衡时，会产生biased tree。因此对非平衡类问题，需要平衡数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持向量机（Support Vector Machine）\n",
    "\n",
    "原理：根据标签数据集在高维数据空间上找到一个超平面（hyper-plane）能将数据集进行分割。一个好的超平面应该是离每个类别最近数据点具有最远距离，因此这个超平面也叫最大边缘超平面（maximal margin hyper-plane）。\n",
    "\n",
    "![maximal margin](./hyperplane.png)\n",
    "\n",
    "对于线性支持向量机，SVM的训练过程是要从训练数据中估计出决策边界的参数$w$和$b$，使得满足以下条件：\n",
    "\n",
    "$w \\cdot x_i + b \\ge 1$ 如果$y_i$ = 1\n",
    "\n",
    "$w \\cdot x_i + b \\le -1$ 如果$y_i$ = -1\n",
    "\n",
    "以上写成紧凑形式如下：\n",
    "\n",
    "$y_i(w \\cdot x_i + b) \\ge 1, i = 1, 2, \\dots, N$  \n",
    "\n",
    "其中$w$和$b$为决策平面参数，$x_i$为第i个训练样本。\n",
    "\n",
    "在支持向量点处有：$y_i(w \\cdot x_i + b) = 1$  \n",
    "\n",
    "那么决策平面的边缘距离为：\n",
    "\n",
    "$d = \\frac{2}{\\parallel w \\parallel}$  \n",
    "\n",
    "于是优化的目标便是是边缘距离最大，即距离的逆最小即：\n",
    "\n",
    "${min}_{w}\\frac{\\parallel{w}\\parallel}{2}$  \n",
    "\n",
    "为了解决数据可能存在噪音，出现过拟合的问题，在约束中引入了松弛向量$\\zeta$，使得：\n",
    "\n",
    "$y_i(w \\cdot x_i + b) \\ge 1 - \\zeta_i, i = 1, 2, \\dots, N$，其中$\\forall{i}: \\zeta_i > 0$  \n",
    "\n",
    "为了限制误分类的数量，优化的目标为：\n",
    "\n",
    "${min}_{w,\\zeta}\\frac{\\parallel{w}\\parallel}{2} + C(\\sum\\limits_{i=1}^N\\zeta_i)^k$  \n",
    "\n",
    "其中$C$和$k$为用户指定参数，表示对误分类训练实例的惩罚系数。在sklearn中$k$为1。\n",
    "\n",
    "对于线性不可分的情况，引入了核函数（Kernel function），将原来样本空间映射到更高维空间，再通过线性决策边界划分样本。\n",
    "\n",
    "核函数的特点是变换后空间的点积可以用原空间的向量来计算，避免了高维空间带来的计算开销。满足Mercer定理的函数，都可以作为核函数：\n",
    "\n",
    ">Mercer定理  核函数$K$可以表示为：$K(u, v) = \\Phi(u) \\cdot \\Phi(v)$，当且仅当对于任意满足$\\int{{g(x)}^2{dx}}$为有限值的函数$g(x)$，使得$\\int{K(x, y)g(x)g(y)dx dy \\ge 0}$  \n",
    "\n",
    "sklearn提供的核函数包括：\n",
    "\n",
    "1. linear: $K(u, v) = u \\cdot v$；  \n",
    "2. polynominal: $K(u, v) = (\\gamma{u} \\cdot v + r)^d$，其中d（degree）、r（coef0）需要用户指定；\n",
    "3. rbf：$K(u, v) = e^{-\\gamma{\\parallel{u - v}\\parallel}^2}$，其中$\\gamma$需要用户指定；\n",
    "4. sigmoid：$tanh(\\gamma{u \\cdot v} + r)$，其中r(coef0)需要用户指定；\n",
    "\n",
    "综上所述，SVM的算法模型如下：\n",
    "\n",
    "$min_{w,\\zeta}\\frac{\\parallel{w}\\parallel}{2} + C\\sum\\limits_{i=1}^{N}\\zeta_i$，其中$w$、$b$、$\\zeta$需满足以下条件：\n",
    "\n",
    "$y_i(w \\cdot K(w_i) + b) \\ge 1 - \\zeta_i$，其中$\\zeta_i \\ge 0, i = 1, 2, \\dots,N$  \n",
    "\n",
    "决策边界函数为：\n",
    "\n",
    "$sign(w \\cdot x + b) = sign(\\sum_{i=1}^n{y_i}\\lambda_i{K(x_i, x)} + b)$  \n",
    "\n",
    "其中$n$为支持向量（support vector）个数，$\\lambda_i$求解以上凸优化问题产生的$\\lambda$系数。在sklearn的SVC模型中，`dual_coef_`存储$y_i{\\lambda_i}$值，`intercept_`存储$b$值。  \n",
    "\n",
    "\n",
    "#### 优点\n",
    "\n",
    "1. 模型对高维数据仍然有效；\n",
    "2. 在维度数超过样本数情况下，模型仍然有效；\n",
    "3. 仅使用支持向量做预测，模型应用时内存占用小；\n",
    "\n",
    "#### 缺点\n",
    "\n",
    "1. 当维度数大大超过样本数时，为了避免过拟合，需要合理选择核函数；  \n",
    "2. SVM对特征缩放比较敏感，在使用SVM模型时，需要将数据标准化；\n",
    "3. SVM不直接提供概率估计，需要通过代价较高的5折交叉验证来估计；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归（Logistic Regression）\n",
    "\n",
    "原理：通过logistic函数将线性拟合的数据结果转换成接近0或者1的二类数据进行分类。其中logistic函数形式如下：\n",
    "\n",
    "$h_{\\theta,b}(x) = \\frac{1}{1 + e^{-(\\theta \\cdot x + b)}}$   \n",
    "\n",
    "![$h(x)=\\frac{1}{1+e^{-x}}$](./logistic_regression.png)\n",
    "\n",
    "这样，我们可以根据logistic函数值来对样本进行分类：\n",
    "\n",
    "$\\hat{y} = \\left\\{\\begin{array}{c}1\\ if\\ h(x) \\ge 0.5\\\\0\\ otherwise\\end{array}\\right.$\n",
    "\n",
    "优化的目标是使代价函数$J(\\theta)$最小：\n",
    "\n",
    "$J(\\theta) = {\\parallel h(x) - y \\parallel}_2 = \\sum_i{(h(x_i) - y_i)}^2$      \n",
    "\n",
    "但由于$J(\\theta)$为非凸函数，导致代价函数有许多局部最小值，不利于求解。\n",
    "\n",
    "![凸函数和非凸函数](./logistic_non_convex.png) \n",
    "\n",
    "为了解决这个问题，我们可以考虑将$h(x)$看作对类1的后验估计，于是有：\n",
    "\n",
    "$p(y=1|x;\\theta) = h(x)$  \n",
    "$p(y=0|x;\\theta) = 1 - h(x)$  \n",
    "\n",
    "上面两式考虑y的取值，可以写成下面紧凑形式：\n",
    "\n",
    "$p(y|x;\\theta) = h(x)^y (1 - h(x))^{(1 - y)}$  \n",
    "\n",
    "有了对类的后验估计，可以用最大似然估计来估计参数$\\theta$  \n",
    "\n",
    "$J(\\theta) = \\prod\\limits_{i=1}^n{p(y|x;\\theta)} = \\prod\\limits_{i=1}^n{h(x_i)^{y_i} (1 - h(x_i))^{(1 - y_i)}}$  \n",
    "\n",
    "为了简化计算，两边取对数，并取负号将最大概率估计问题变成代价函数最小问题：\n",
    "\n",
    "$L(\\theta) = -log(J(\\theta)) = -\\sum\\limits_{i=1}^{n}(y_i{log(h(x_i))} + (1 - y_i)log{(1 - h(x_i))})$  \n",
    "\n",
    "\n",
    "--[逻辑回归](https://blog.csdn.net/zjuPeco/article/details/77165974)\n",
    "\n",
    "为了避免出现过拟合，加入了正则化处理（regularization)：\n",
    "\n",
    "$L(\\theta) = -\\sum\\limits_{i=1}^{n}(y_i{log(h(x_i))} + (1 - y_i)log{(1 - h(x_i))}) + \\lambda{\\parallel \\theta \\parallel}_2$  \n",
    "\n",
    "上式便是逻辑回归参数学习所用到的数学模型。需要指出的是，该公式与sklearn官方文档提供的公式虽然形式貌似不同，但实际是等价的。sklearn提供的LogisticRegression是将将类标记为{1, -1}，而不是{1, 0}，所以会有形式上差别。\n",
    "\n",
    "优点：\n",
    "\n",
    "1. 直接输出概率估计，容易理解；\n",
    "2. 可以根据新数据采用随机梯度下降方法快速更新模型，适合实现在线学习；\n",
    "\n",
    "缺点：\n",
    "\n",
    "1. 逻辑回归本质是发现潜在的线性关系，无法描述复杂的关系；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯（Naive Bayes）\n",
    "\n",
    "贝叶斯定理：$P(Y|X) = \\frac{P(Y)P(X|Y)}{P(X)}$  \n",
    "贝叶斯分类器模型：$\\hat{y} = \\underset{k\\in\\{1,\\dots,K\\}}{argmax} p(C_k)\\prod\\limits_{i=1}^n p(x_i \\mid C_k)$，找到使后验概率最大类别$C_k$    \n",
    "\n",
    "*注意*：贝叶斯分类器假定所有特征都是独立的，所以有$p(x_i \\mid x_{i+1},\\dots,x_n,C_k) = p(x_i \\mid C_k)$成立  \n",
    "\n",
    "高斯贝叶斯(Gaussian naive Bayes)：假定与每个类别关联的特征都服从高斯正态分布，则$p(x = v \\mid C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_k}}e^{-\\frac{(v - \\mu_k)^2}{2\\sigma^2_k}}$  \n",
    "多项贝叶斯(Multinomial naive Bayes): 假定与每个类别关联的样本（即n维特征向量）表示的是某个n维多项分布产生的频率。则：\n",
    "\n",
    "$p(\\textbf{x}\\mid C_k) = \\frac{(\\sum_i{x_i})!}{\\prod_i{x_i}!}\\prod\\limits_{i}p_{ki}^{x_i}$  \n",
    "\n",
    "伯努利贝叶斯：当特征都是布尔型变量时，多项贝叶斯变为伯努利贝叶斯，此时：\n",
    "\n",
    "$p(\\textbf{x}\\mid C_k) = \\prod\\limits_{i=1}^n p_{ki}^{x_i}(1 - p_{ki})^{(1 - x_i)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机梯度下降（SGD）\n",
    "\n",
    "原理：SGD将分类任务描述成以下形式：\n",
    "\n",
    "给定训练集$(x_1, y_1),\\dots,(x_n, y_n)$，其中$x_i \\in \\textbf{R}^m$，$y_i \\in \\{-1, 1\\}$，分类误差用以下公式表示：\n",
    "\n",
    "$E(\\omega, b) = \\frac{1}{n}\\sum\\limits_{i=1}^{n}L(y_i, f(x_i)) + \\alpha R(\\omega)$\n",
    "\n",
    "其中$f(x_i)=\\omega \\cdot x + b$为线性拟合函数，$L$为度量模型拟合误差损失函数（Loss function)，$R$为采用的正则函数（用于防止过拟合），$\\omega$为非负的超参数。值得一提的是，$b$在sklearn中称作intercept，截距。\n",
    "\n",
    "\n",
    "为了求解最小化分类误差的参数，采用梯度下降的方法，每次都会根据当前$\\omega$的梯度下降方向调整$\\omega$参数，使得分类误差$E(\\omega, b)$减少最快：\n",
    "\n",
    "$\\omega \\leftarrow \\omega - \\eta \\nabla E(\\omega, b) = \\omega - \\eta (\\frac{1}{n}\\sum\\limits_{i=1}^{n}\\nabla L(y_i, f(x_i)) + \\alpha \\nabla R(\\omega))$    \n",
    "\n",
    "其中$\\eta$为学习率（learning rate），控制梯度下降的快慢。但上式每次更新$\\omega$都要计算每个训练样本的梯度，计算量非常大。因此，SGD使用采样的方法，每次只是选取部分样本计算梯度，用这些样本的梯度和来近似$E(\\omega, b)$的梯度。\n",
    "\n",
    "当采样为1时，即每次只用一个训练样本更新参数，便为随机梯度（Stochastic gradient descent)；如果采样为$N > 1$，则为batch gradient descent。\n",
    "\n",
    "SGD具体做法是每次迭代一个样本，更新参数：\n",
    "\n",
    "$\\omega \\leftarrow \\omega - \\eta(\\alpha \\frac{\\partial R(\\omega)}{\\partial \\omega} + \\frac{\\partial L(\\omega \\cdot x_i + b, y_i)}{\\partial \\omega})$  \n",
    "\n",
    "采用SGD时，需要合理选择学习率$\\eta$，$\\eta$设置太高，会导致不收敛；设置太低，收敛速度过慢。因此，出现一些改进算法，比如Momentum，AdaGrad，Adam这样的算法，动态更新$\\eta$。\n",
    "\n",
    "#### 优点\n",
    "\n",
    "1. 算法高效，易于实现；\n",
    "2. 可以支持在线学习；\n",
    "\n",
    "#### 缺点\n",
    "\n",
    "1. 算法需要很多参数调整，比如正则函数选择、学习率、迭代次数、$\\alpha$系数等；\n",
    "2. 算法对特征缩放比较敏感；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最近邻（Nearest Neighbors）\n",
    "\n",
    "原理：不从训练数据中学习参数，而是在训练样本集中搜索与当前样本距离最近的一组样本，用这组样本的标签来预测当前样本。样本组的大小可以固定为常量，即为K近邻算法；也可以基于局部密度变化，如sklearn提供的RadiusNeighborsClassifier，在固定半径周围搜索样本。\n",
    "\n",
    "为了提供搜索效率，sklearn提供了3种算法：\n",
    "\n",
    "1. brute force。暴力检索，待分类样本与训练集中每个样本计算距离，然后找出最近的样本，算法复杂度为$O(DN^2)$，其中$D$为样本维度数;  \n",
    "2. K-D tree。基于这样的想法：如果点A离点B比较远，而点B与点C比较近，就可以知道点A肯定离点C也比较远，不用实际去计算点A与点C。K-D tree平均将算法复杂度下降到$O(DNlog(N))$，但如果D很大，K-D tree复杂度反而会提高，甚至比brute force还慢；  \n",
    "3. Ball Tree。是K-D tree的改进算法，解决D很大的情况。与K-D tree相比，树的构造计算量较大，但是检索效率在高维空间比较高。  \n",
    "\n",
    "预测样本时，可以选择邻居样本中出现次数最大的标签，或者按照距离加权输出最终标签。\n",
    "\n",
    "优点\n",
    "\n",
    "1. 算法理解简单，易于实现；\n",
    "2. 如果训练数据集比较大，算法比较高效\n",
    "\n",
    "缺点\n",
    "\n",
    "1. 需要合理设定K值，即邻居的数量；  \n",
    "2. 如何合理选择距离的度量；  \n",
    "3. 当训练样本比较大时，数据存储占用较多；\n",
    "4. 该算法对特征的缩放比较敏感；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络\n",
    "\n",
    "#### 感知器（perceptron）\n",
    "![perceptron](./perceptron.png)\n",
    "\n",
    "感知器是接收多个二元输入，产生一个二元输出的结构，输出与输入关系如下：\n",
    "\n",
    "$output = \\left\\{\\begin{array}{cc}{0}\\ {if \\sum_j{w_jx_j} + b \\le 0}\\\\{1}\\ {if \\sum_j{w_jx_j} + b > 0}\\end{array}\\right. $\n",
    "\n",
    "\n",
    "#### sigmoid神经元（sigmoid neuron）\n",
    "\n",
    "感知器存在一个问题，由于采用阈值判断，输入的微小变动会导致截然不同的输出值。sigmoid神经元采用sigmoid函数代替阶跃函数，使输出更加平滑：\n",
    "\n",
    "$output = \\frac{1}{1 + exp{-(\\sum_jw_jx_j + b)}}$\n",
    "\n",
    "![sigmoid function](./sigmoid.png)\n",
    "\n",
    "#### 前馈神经网络（forward neuron network）\n",
    "\n",
    "多层sigmoid神经元形成一个网络如下，由一个输入层（input layer）、2个隐藏层（hidden layer）和一个输出层（output layer）。由于每一层的输入来自于上一层的输出，这种网络被称为前馈神经网络。由于历史原因，这类网络在有的文献又称为多层感知器（multilayer perceptrons，MLP），虽然用的神经元已经是sigmoid，而不是感知器。\n",
    "\n",
    "![forward neuron network](./neural_network.png)\n",
    "\n",
    "使用神经网络作为分类模型，需要根据分类误差不断优化权重和偏置（bias）参数，其损失函数（Mean Square Error，MSE）定义如下：\n",
    "\n",
    "$C(w, b) = \\frac{1}{n} \\sum_x{C_x} = \\frac{1}{2n}\\sum_x{\\parallel y(x) - a\\parallel}^2$  \n",
    "\n",
    "其中$w$表示网络所有权重，b是所有的偏置，n是训练样本的大小，a是输入向量x在神经网络中的输出，y(x)是输入向量x的期望输出。\n",
    "\n",
    "神经网络参数训练的目的是使损失函数$C(w, b)$最小，训练的基本思想是采用梯度下降的方法，先随机初始化$w$和$b$，然后按照$C$的梯度下降方向更新：\n",
    "\n",
    "$w_k \\rightarrow w_k' = w_k - \\eta \\frac{\\partial C}{\\partial w_k}$  \n",
    "\n",
    "$b_l \\rightarrow b_l' = b_l - \\eta \\frac{\\partial C}{\\partial b_l}$  \n",
    "\n",
    "直接计算$C$的梯度当训练样本很大时，计算量非常大，因为$\\nabla C = \\frac{1}{n}\\sum_x{C_x}$，为此使用随机梯度下降的方法，随机选择部分样本用来近似$C$的梯度，因此就有：\n",
    "\n",
    "$\\nabla C =  \\frac{\\sum_x \\nabla C_x}{n} \\approx \\frac{1}{m}\\sum_{j=1}^m {\\nabla C_{X_j}}$  \n",
    "\n",
    "其中$m$为随机选取的样本大小，又叫batch size。\n",
    "\n",
    "于是梯度更新方法修改为：\n",
    "\n",
    "$w_k \\rightarrow w_k' = w_k - \\frac{\\eta}{m} \\sum\\limits_j\\frac{\\partial C_{X_j}}{\\partial w_k}$\n",
    "\n",
    "$b_l \\rightarrow b_l' = b_l - \\frac{\\eta}{m} \\sum\\limits_j\\frac{\\partial C_{X_j}}{\\partial b_l}$\n",
    "\n",
    "\n",
    "为了快速计算$C$的偏导数，发明了反向传播的算法，算法如下：\n",
    "\n",
    "1. 初始化$a^1$：\n",
    "\n",
    "    $a^{x,1} = x$\n",
    "\n",
    "2. 前馈计算\n",
    "\n",
    "    $a^{x,l}$：$z^{x,l} = w^l a^{x,l-1} + b^l,  a^{x,l} = \\sigma(z^{x,l}), l = 2,3,\\dots,L$，其中$L$为神经网络层数，输入层算第一层，$a^l$表示第$l$层输出（activation output），$z^l$表示第$l$层的加权输入（weighted input）\n",
    "\n",
    "3. 计算输出层误差$\\delta^L$\n",
    "\n",
    "    $\\delta^{x,L} \\equiv \\frac{\\partial C}{\\partial z^l} = \\nabla_a C_x \\odot \\sigma'(z^{x,L}) = (a^L - y) \\odot \\sigma'(z^{x,L})$，其中$\\odot$为Hadamard积，表示2个向量间的element-wise product，即$(s\\odot t)_j =s_j * t_j$   \n",
    "\n",
    "4. 反向传播误差\n",
    "\n",
    "    $\\delta^{x,l} = ((w^{l+1})^T \\delta^{x,l+1}) \\odot \\sigma'(z^{x,L}), l = L - 1, L - 2, ..., 2$\n",
    "\n",
    "5. 输出梯度\n",
    "\n",
    "    $\\frac{\\partial C_x}{\\partial w_{jk}^l} = a_k^{x,l-1} \\delta_j^{x,l}, \\frac{\\partial C_x}{\\partial b_j^l} = \\delta_j^{x,l}$ \n",
    "    \n",
    "采用反向传播算法，随机梯度的更新方法修改为：\n",
    "\n",
    "$w^l \\rightarrow w^l - \\frac{\\eta}{m}\\sum_x{\\delta^{x, l}(a^{x, l-1})^T}$  \n",
    "\n",
    "$b^l \\rightarrow b^l - \\frac{\\eta}{m}\\sum_x{\\delta^{x,l}}$  \n",
    "\n",
    "\n",
    "#### 交叉熵损失函数（cross entropy loss function）\n",
    "\n",
    "采用MSE作为神经网络误差损失函数，当$w$和$b$初始化为不同值时，会产生不同的梯度下降速度，被称为“learning slowdown”，为了解决这个问题，可以采用交叉熵作为神经网络的损失函数。\n",
    "\n",
    "$C(w,b) = -\\frac{1}{n}\\sum\\limits_x\\sum\\limits_j{(y_j ln a_j^L + (1 - y_j)ln(1 - a_j^L))}$\n",
    "\n",
    "使用交叉熵作为损失函数，采用反向传播算法，其输出层误差变为：\n",
    "\n",
    "$\\delta^L = a^L - y$  \n",
    "\n",
    "可以看到与MSE相比，原来计算$\\delta^L$包含的成分$\\sigma'(z^L)$消失了，误差与预测误差成正比     \n",
    "\n",
    "#### softmax函数\n",
    "\n",
    "解决“learning slowdown”的另一个方法，是采用softmax层代替sigmoid层作为输出层，使用softmax函数代替sigmoid函数，softmax函数形式如下：\n",
    "\n",
    "$a_j^L = \\frac{e^{z_j^L}}{\\sum_k{e^{z_k^L}}}$  \n",
    "\n",
    "softmax函数具有以下性质：\n",
    "\n",
    "1. 输出层所有神经元的输出都是正的（positive），在（0，1）区间；  \n",
    "2. 输出层所有神经元的输出总和是1，我们可以把softmax层的输出看成输出值的概率分布；\n",
    "3. 输出层每个神经元的输出都依赖于输出层所有神经元的加权输入；\n",
    "\n",
    "使用softmax层，需要配合使用对数似然函数（log-likelihood)作为训练神经网络的损失函数：\n",
    "\n",
    "$C \\equiv -\\sum\\limits_x{ln a_y^L}$  \n",
    "\n",
    "采用反向传播，此时输出层误差为：\n",
    "\n",
    "$\\delta^L = a^L - y$  \n",
    "\n",
    "*注*：一般情况下，sigmoid + cross entropy与softmax + log-likehood方法在大多数情况效果是一样的。softmax层使得网络输出更容易解释。\n",
    "\n",
    "\n",
    "#### 正则化\n",
    "\n",
    "由于神经网络包含很多参数，尤其是多层神经网络，为了防止过拟合，可以通过增加训练样本数量、减少网络规模，以及引入正则化、dropout技术来降低过拟合。\n",
    "\n",
    "正则化是在原loss function中增加正则项，对网络的复杂度进行惩罚。其中L2正则化形式为：\n",
    "\n",
    "$C = C_0 + \\frac{\\lambda}{2n}\\sum\\limits_w{w^2}$  \n",
    "\n",
    "其中$C_0$为原始loss function，$\\lambda$为正则化参数（regularization parameter）。\n",
    "\n",
    "L1正则化形式为：\n",
    "\n",
    "$C = C_0 + \\frac{\\lambda}{n}\\sum\\limits_w|w|$  \n",
    "\n",
    "\n",
    "#### dropout\n",
    "\n",
    "dropout技术是一种特殊正则化技术，它不修改原始的loss function，而是通过修改网络本身来防止过拟合。具体的操作过程是：\n",
    "\n",
    "在每次通过mini-batch更新权重时，先随机地删掉一定比例的隐藏层神经元，然后在修改后的网络进行前馈计算、反向传播，更新权重；更新完权重后，再恢复删掉的隐藏层神经元，接着随机删掉一定比例的隐藏层神经元，进入下一个mini-batch的权重更新流程，重复这样的过程。\n",
    "\n",
    "在dropout过程中，被临时删掉的神经元被称作dropout neurons。\n",
    "\n",
    "优点：\n",
    "    1. 学习能力强，可以拟合非线性等复杂模型；\n",
    "    2. 支持在线学习；\n",
    "    \n",
    "缺点：\n",
    "    1. 神经网络的损失函数一般是非凸函数，存在多个局部最优解。不同的权重初始化会导致不同的应用效果；\n",
    "    2. 神经网络有大量的参数需要调优；\n",
    "    3. 对特征缩放比较敏感，应用时需要将特征进行归一化处理；\n",
    "\n",
    "--[神经网络与深度学习](http://neuralnetworksanddeeplearning.com/chap1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合方法\n",
    "\n",
    "组合方法的基本思想是通过组合多个弱分类器的预测结果来提升整体效果，构建组合分类器有以下几种思路：\n",
    "\n",
    "1. 通过处理训练数据集。这种方法根据某种抽样分布，通过原始数据进行再抽样来得到多个训练集，然后使用特定的学习算法为每个训练集建立一个分类器。装袋（Bagging）和提升（Boosting）都属于这种方法；\n",
    "\n",
    "2. 通过处理输入特征。这种方法通过选择输入特征的子集来形成每个训练集，随机森林采用了这种方法；\n",
    "\n",
    "3. 通过处理类标号。适用于类别比较多的情况，将类标号重新编码，将训练数据变为二类问题，比如错误-纠正输出编码（error-correcting output coding），将类标号表示成二进制位串，针对每一位构造一个分类器，最后将每个分类器的输出组合成一个位串得出类标号；\n",
    "\n",
    "4. 通过处理学习算法。比如可以通过改变一个神经网络的拓扑结构或者各个神经元之间联系的初始权值；或者通过在树生成过程中注入随机性，得到决策树的组合分类器；\n",
    "\n",
    "多个分类器组合在一起对样本进行预测时，可以通过多数表决的方式，或者根据分类器的准确率进行加权，得到最终的类标号。\n",
    "\n",
    "组合方法通常分为2类：\n",
    "\n",
    "1. averaging方法。它的原理是独立地构建多个分类器，然后平均它们的预测结果。一般来说，组合的分类器通常逗比单个分类器效果要好，因为减少了方差。代表方法有Bagging、Random Forest。\n",
    "\n",
    "2. 提升方法（Boosting）。分类器顺序构建，后一个分类器根据前一个分类器误差来构建，通过减少分类器的bias来提升性能。代表方法有AdaBoost、GBDT等。\n",
    "\n",
    "#### Bagging（Bootstrap Aggregating）\n",
    "\n",
    "通过随机抽取训练样本的子集构造多个分类器，聚合（aggregate）多个分类器的预测结果来最终预测。获取训练样本子集有多种方法，sklearn提供的BaggingClassifier支持以下几种：\n",
    "\n",
    "1. 通过无放回抽样产生子集（Pasting）；\n",
    "\n",
    "2. 通过有放回抽样产生子集（Bagging）；\n",
    "\n",
    "3. 通过随机选择特征子集（Random Subspaces）组成训练样本子集；\n",
    "\n",
    "4. 既随机有放回抽样，又随机选择特征组成训练样本子集（Random Patches）；\n",
    "\n",
    "采用Bagging方法，可以减少过拟合，同时减少预测的方差。Bagging方法一般选择强的复杂的模型，比如完全生长树（full developed decision tree），而提升方法一般选择弱的模型，比如shallow decision tree。\n",
    "\n",
    "![single tree vs bagging(tree)](./bagging.png)\n",
    "\n",
    "#### 随机森林（Random Forest）\n",
    "\n",
    "随机森林与Bagging相比，不仅采用有放回抽样产生多个训练样本子集，在节点分割（split node）时会随机选择特征子集来确定最佳划分。一般，随机森林相对于单一非随机树而言，bias会略微增加，但是由于平均作用（averaging）随机森林的方差相对于bias显著减少，从而产生更好的模型。\n",
    "\n",
    "sklearn提供了另外一种随机森林算法（Extremely Randomized Tree），与Random Forest相比，在节点分割时也是随机选择特征子集来确定划分，但是划分时，没有像随机森林需要找到最佳划分threshold，而是为每一个候选特征随机选择一个threhold，再在所有候选特征子集中选择最佳划分。相对于Random Forest而言，会进一步减少方差，但bias也会略微增加。\n",
    "\n",
    "*注*：Random Forest可以并行执行，可以运行在多个核上。\n",
    "\n",
    "#### AdaBoost\n",
    "\n",
    "基本思想是后一个分类器根据前一个分类器的分类误差调整样本权重，刚开始时每个样本的权重相同$w_i = \\frac{1}{N}$，训练一个弱分类器$h_t(x)$，根据分类器的分类误差确定该分类器的权重$\\alpha_t$，并根据分类效果调整每个样本的权重，分类错的样本权重加大，分类对的样本权重减小，然后重新一个训练新的分类器$h_{t+1}(x)$，迭代多次，产生$T$个分类器，最终分类器为这$T$个分类器的加权线性组合：\n",
    "\n",
    "$H(x) = sign(\\sum\\limits_{t=1}^T{\\alpha_t h_t(x)})$  \n",
    "\n",
    "优点：\n",
    "    1. 分类性能好；\n",
    "    \n",
    "缺点：\n",
    "    1. 无法并行执行，只能顺序执行；\n",
    "    2. 对噪声数据和异常点比较敏感；\n",
    "\n",
    "--[一文读懂AdaBoost](http://www.xtecher.com/Xfeature/view?aid=8109)\n",
    "\n",
    "#### GBDT（Gradient Boosting Decision Tree）\n",
    "\n",
    "基本思想是对上一个分类器$F_m(x)$的残差采用决策树进行拟合得到拟合函数$h(x)$，然后将$F_{m+1}(x) = F_m(x) + h(x)$作为新的分类器，重复上述过程N次，得到的分类器$F_N(x)$作为最终GBDT得到的分类器。\n",
    "\n",
    "优点\n",
    "    1. 优异的预测性能；\n",
    "    2. 对噪声数据和异常点不敏感；\n",
    "    \n",
    "缺点\n",
    "    1. 很难并行化；\n",
    "    \n",
    "\n",
    "--[Gradient boosting Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)\n",
    "\n",
    "#### XGBoost（Extreme Gradient Boosting）\n",
    "\n",
    "XGBoost是实现gradient boosting框架的软件库，提供可扩展、可移植、分布式gradient boosting库，与sklearn提供的GBDT相比，增加了正则项来防止过拟合，提升了性能；另外内存占用更小，支持并行训练，速度更快。\n",
    "\n",
    "--[XGBoost paper](https://arxiv.org/pdf/1603.02754.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归算法\n",
    "\n",
    "## 线性回归（Linear Regression）\n",
    "\n",
    "基本思想是将目标变量看成输入变量的线性组合，通过训练样本找到最佳的权重使误差最小。数学形式表述为：\n",
    "\n",
    "$\\hat{y}(\\omega, x) = \\omega_0 + \\omega_1 x_1 + \\dots + \\omega_p x_p$  \n",
    "\n",
    "损失函数为：\n",
    "\n",
    "$L(\\omega) = {\\parallel X \\omega - y \\parallel}_2^2$\n",
    "\n",
    "该方法也被通俗称为“最小二乘法”。\n",
    "\n",
    "## 岭回归（Ridge Regression）\n",
    "\n",
    "为了防止线性回归过拟合，Ridge Regression引入L2正则项，对线性拟合系数大小进行惩罚。\n",
    "\n",
    "$L(\\omega) = {\\parallel X \\omega - y \\parallel}_2^2 + \\alpha {\\parallel \\omega \\parallel}_2^2$  \n",
    "\n",
    "其中$\\alpha \\ge 0$为惩罚系数，越大拟合出的系数越小。\n",
    "\n",
    "## Lasso回归\n",
    "\n",
    "Lasso回归是在线性回归基础上引入了L1正则项，如下：\n",
    "\n",
    "$L(\\omega) = {\\parallel X \\omega - y \\parallel}_2^2 + \\alpha {\\parallel \\omega \\parallel}_1$  \n",
    "\n",
    "其中$\\alpha \\ge 0$为惩罚系数。采用Lasso回归时，得到系数很多会是0，可以起到特征筛选的作用。\n",
    "\n",
    "## 其它基于分类的回归\n",
    "\n",
    "很多分类算法通过扩展可以用在回归问题上，下面说明下应用在回归问题上的思路。\n",
    "\n",
    "### 决策树\n",
    "\n",
    "使用决策树做回归分析时，采用Mean Squared Error（MSE）或者Mean Absolute Error（MAE）作为节点不纯性度量的函数，仍然采用增益最大选择最优划分。\n",
    "\n",
    "Mean Squared Error：\n",
    "\n",
    "$c_m = \\frac{1}{N_m}\\sum\\limits_{i \\in N_m}y_i$\n",
    "\n",
    "$I(X_m) = \\frac{1}{N_m}\\sum\\limits_{i \\in N_m}(y_i - c_m)^2$\n",
    "\n",
    "Mean Absolute Error:\n",
    "\n",
    "$I(X_m) = \\frac{1}{N_m}\\sum\\limits_{i \\in N_m}|y_i - c_m|$\n",
    "\n",
    "其中$X_m$为节点m中的训练样本，$N_m$为节点m包含的训练样本集合大小\n",
    "\n",
    "预测时，选择叶子节点包含样本的均值作为预测值。\n",
    "\n",
    "\n",
    "### 支持向量机\n",
    "\n",
    "使用支持向量机进行回归分析的算法，一般称作$\\varepsilon-SVM$回归算法，该算法的思想是找到线性函数$f(x)$，使得该函数对于每一个训练样本$x_i$，其预测值$f(x_i)与$真实值$y_i$的偏差不超过$\\varepsilon$，同时函数$f(x)$尽可能平坦。用数学描述如下：\n",
    "\n",
    "$f(x) = w \\cdot x + b$\n",
    "\n",
    "$|y_i - f(x_i)| \\le \\varepsilon, i = 1,2,\\dots,N$\n",
    "\n",
    "优化目标：\n",
    "\n",
    "$min_w\\frac{\\parallel w \\parallel}{2}$\n",
    "\n",
    "与分类SVM一样，为了解决数据可能存在的噪音，出现过拟合的问题，在约束中引入了松弛向量$\\zeta$和$\\zeta^*$：\n",
    "\n",
    "$min_{w,\\zeta,\\zeta^*}\\frac{\\parallel w \\parallel}{2} + C\\sum\\limits_{i=1}^{N}(\\zeta_i + \\zeta_i^*)$ \n",
    "\n",
    "其中：\n",
    "\n",
    "$y_i - f(x_i) \\le \\varepsilon + \\zeta_i$\n",
    "\n",
    "$f(x_i) - y_i \\le \\varepsilon + \\zeta_i^*$\n",
    "\n",
    "$\\zeta_i, \\zeta_i^* \\ge 0$\n",
    "\n",
    "![SVR](./svr.png)\n",
    "\n",
    "与分类SVM一样，SVR也支持核函数，处理非线性问题。\n",
    "\n",
    "--[Understanding support vector machine regression](https://cn.mathworks.com/help/stats/understanding-support-vector-machine-regression.html)\n",
    "\n",
    "### 随机梯度下降\n",
    "\n",
    "SGD用于回归问题与用于分类问题的思路是一样的，试图找到线性函数$f(x)=\\omega \\cdot x + b$使得回归误差最小：\n",
    "\n",
    "$min_{\\omega, b}E(\\omega, b) = min_{\\omega, b}\\frac{1}{n}\\sum_{i=1}^{n}L(y_i, f(x_i)) + \\alpha R(\\omega)$\n",
    "\n",
    "其中$L$为度量回归误差的函数，$R$为采用的正则函数（用于防止过拟合）。\n",
    "\n",
    "### K近邻\n",
    "\n",
    "K近邻回归分析原理与分类原理类似，用与测试样本最近的训练样本值来预测。预测时使用邻居的平均值，或者加权平均值作为预测输出。\n",
    "\n",
    "K近邻做回归分析，sklearn也提供2种方法，KNeighborsRegressor和RadiusNeighborsRegressor。\n",
    "\n",
    "### 随机森林\n",
    "\n",
    "采用随机森林做回归分析，与决策树应用在回归分析的思路一致，采用MSE、MAE作为节点不纯性度量的函数，预测时，选择叶子节点包含样本的均值作为预测值。\n",
    "\n",
    "### AdaBoost\n",
    "\n",
    "原理与分类问题一致。\n",
    "\n",
    "### GBDT\n",
    "\n",
    "原理与分类问题一致。\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "同上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习问题解题步骤\n",
    "\n",
    "1. 分析问题类型，确定分析方法。首先需要确定问题是分类问题、回归问题；\n",
    "2. 探索问题\n",
    "\n",
    "    1. 查看数据类型；\n",
    "    2. 查看数据是否有缺失值；\n",
    "    3. 查看数据分布。对于Categorical类型数据，查看频数分布；对于Numerical数据查看均值、方差等分布；\n",
    "    4. 如果是分类问题，查看数据是否平衡；\n",
    "    \n",
    "3. 数据预处理\n",
    "\n",
    "    1. 缺失值处理。处理方法使用DataFrame的fillna函数，或者scikit-learn提供的Imputer；\n",
    "    2. 异常值处理；\n",
    "    3. 特征归一化。处理方法有MinMaxScaler、RobustScaler、StandardScaler；\n",
    "    4. Categorial类型数据处理。处理方法有LabelEncoder、OneHotEncoder、pd.get_dummies；\n",
    "    5. 不平衡类处理。处理方式包括使用sklearn.utils.resample函数进行过采样或欠采样，或者使用模型提供的class_weight参数进行代价敏感学习或者选择可以抗imbalance数据集的模型，比如随机森林、梯度提升树；\n",
    "    6. 日期数据处理。处理方式有2种，如果日期类型的特征比较多，可以将datetime类型通过toordinal()函数变成序数；如果只有几个，可以提取hour of the day、day of the week、day of the month、month of the year、year这些特征；或者如果日期数值比较少，可以直接将日期按照Categorical类型数据处理；\n",
    "    \n",
    "4. 特征选择。选择方法一是根据领域经验，选择最有可能影响目标的特征；二是通过算法的方式，可以使用sklearn提供的SelectKBest、SelectFdr、SelectFromModel来选择；\n",
    "\n",
    "5. 训练模型。选用合适的模型，然后调用模型fit函数。sklearn提供了Pipeline函数，可以将多个操作步骤chain在一起，另外可以配合GridSearch函数，优化模型参数。\n",
    "\n",
    "6. 评估模型。对于分类问题，常用的评分函数有准确率（precision rate)、召回率（recall_score)、F1得分和ROC曲线下面积AUC值。对于回归问题，常用的评分函数有解释方差得分（explained variance score）、平均绝对误差（Mean absolute error，MAE），平均平方误差（Mean squared error， MSE）和方差百分率（r2 score）。\n",
    "\n",
    "$precision = \\frac{tp}{tp+fp}$\n",
    "\n",
    "$recall = \\frac{tp}{tp+fn}$\n",
    "\n",
    "$F1 = \\frac{2 * precision * recall}{precision + recall}$\n",
    "\n",
    "$explained\\_variance\\_score = 1 - \\frac{Var(y - \\hat{y})}{Var(y)}$\n",
    "\n",
    "$MAE = \\frac{1}{N}\\sum\\limits_{i=1}^{N}|y_i - \\hat{y_i}|$\n",
    "\n",
    "$MSE = \\frac{1}{N}\\sum\\limits_{i=1}^{N}(y_i - \\hat{y_i})^2$\n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2}{\\sum\\limits_{i=1}^{N}(y_i - \\bar{y})}$，其中$\\bar{y}=\\frac{\\sum\\limits_{i=1}^{N}y_i}{N}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
